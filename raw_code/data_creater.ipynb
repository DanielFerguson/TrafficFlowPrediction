{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler,normalize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(file, lags):\n",
    "    \"\"\"Process data\n",
    "    Reshape and split train\\test data.\n",
    "    # Arguments\n",
    "        train: String, name of .csv train file.\n",
    "        test: String, name of .csv test file.\n",
    "        lags: integer, time lag.\n",
    "    # Returns\n",
    "        X_train: ndarray.\n",
    "        y_train: ndarray.\n",
    "        X_test: ndarray.\n",
    "        y_test: ndarray.\n",
    "        scaler: StandardScaler.\n",
    "    \"\"\"\n",
    "    \n",
    "#     read csv file\n",
    "    df = pd.read_csv(\"/Users/ditlswin/Documents/rkaul/traffic_flow_predi/TrafficFlowPrediction-master/data/{}\".format(file), encoding='utf-8',header=None).fillna(0)\n",
    "\n",
    "#   read all the vehicle/15min in one array   \n",
    "    flow = np.array(df.iloc[:,3:])\n",
    "    flow = flow.ravel()\n",
    "\n",
    "    \n",
    "#     normalize all the values  \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1)).fit(flow.reshape(-1, 1))\n",
    "    normalized_flow = scaler.transform(flow.reshape(-1, 1)).reshape(1, -1)[0]\n",
    "    \n",
    "\n",
    "#     splitting the file into train and test dataset\n",
    "    split = int(normalized_flow.shape[0] * 0.8)\n",
    "    \n",
    "    flow1 = normalized_flow[:split]\n",
    "    flow2 = normalized_flow[split:]\n",
    "    \n",
    "    \n",
    "    train, test = [], []\n",
    "    for i in range(lags, len(flow1)):\n",
    "        train.append(flow1[i - lags: i + 1])\n",
    "    for i in range(lags, len(flow2)):\n",
    "        test.append(flow2[i - lags: i + 1])\n",
    "\n",
    "    train = np.array(train)\n",
    "    print(train)\n",
    "    test = np.array(test)\n",
    "    np.random.shuffle(train)\n",
    "\n",
    "    X_train = train[:, :-1]\n",
    "    print(X_train.shape)\n",
    "    y_train = train[:, -1]\n",
    "    print(y_train.shape)\n",
    "    X_test = test[:, :-1]\n",
    "    y_test = test[:, -1]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.19111111 0.18444444 0.11555556 ... 0.03555556 0.05333333 0.05555556]\n",
      " [0.18444444 0.11555556 0.12888889 ... 0.05333333 0.05555556 0.05555556]\n",
      " [0.11555556 0.12888889 0.13111111 ... 0.05555556 0.05555556 0.03333333]\n",
      " ...\n",
      " [0.64888889 0.74444444 0.72222222 ... 0.78888889 0.73555556 0.66444444]\n",
      " [0.74444444 0.72222222 0.76444444 ... 0.73555556 0.66444444 0.60666667]\n",
      " [0.72222222 0.76444444 0.83333333 ... 0.66444444 0.60666667 0.53333333]]\n",
      "(2368, 12)\n",
      "(2368,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test, scaler = process_data(\"970_1_data.csv\", 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02346145 0.02049874 0.02049874 ... 0.01145047 0.00872798 0.0101693 ]\n",
      " [0.00056051 0.00064059 0.00048044 ... 0.00112103 0.00248227 0.00248227]\n",
      " [0.0012011  0.00072066 0.00072066 ... 0.00072066 0.00032029 0.00088081]\n",
      " ...\n",
      " [0.00216198 0.00216198 0.00128117 ... 0.00064059 0.00040037 0.00024022]\n",
      " [0.0012011  0.00112103 0.00040037 ... 0.00080073 0.0020819  0.00200183]\n",
      " [0.00136124 0.0012011  0.00088081 ... 0.00072066 0.0012011  0.00128117]] [0.01040952 0.00504461 0.00136124 ... 0.00056051 0.00352322 0.00144132]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
