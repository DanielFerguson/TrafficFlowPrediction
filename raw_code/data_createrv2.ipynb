{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler,normalize\n",
    "from datetime import date, timedelta,datetime\n",
    "\n",
    "\n",
    "NUMERIC_DAY = 96 #4(15 min per hour) * 24(for 24 hours) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weekend_data(sdate,edate):\n",
    "    sdate =  datetime.strptime(sdate,'%d/%m/%Y').date()\n",
    "    edate =  datetime.strptime(edate,'%d/%m/%Y').date()\n",
    "    time_period = edate - sdate\n",
    "    weekend = []\n",
    "    for i in range(time_period.days + 1):\n",
    "        day = sdate + timedelta(days=i)\n",
    "        if day.weekday() > 4:\n",
    "            weekend.append(1)\n",
    "        else:\n",
    "            weekend.append(0)\n",
    "    return weekend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rain_data(rain_date,rain,dates):\n",
    "    rain_dict = dict(zip(rain_date,rain))\n",
    "    \n",
    "    updated_rain = []\n",
    "    for date in dates:\n",
    "        updated_rain.append(rain_dict[date])\n",
    "    print(updated_rain)\n",
    "    return updated_rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(file, lags):\n",
    "    \"\"\"Process data\n",
    "    Reshape and split train\\test data.\n",
    "    # Arguments\n",
    "        train: String, name of .csv train file.\n",
    "        test: String, name of .csv test file.\n",
    "        lags: integer, time lag.\n",
    "    # Returns\n",
    "        X_train: ndarray.\n",
    "        y_train: ndarray.\n",
    "        X_test: ndarray.\n",
    "        y_test: ndarray.\n",
    "        scaler: StandardScaler.\n",
    "    \"\"\"\n",
    "    \n",
    "#     read csv file\n",
    "    df = pd.read_csv(\"/Users/ditlswin/Documents/rkaul/traffic_flow_predi/TrafficFlowPrediction-master/data/{}\".format(file), encoding='utf-8',header=None).fillna(0)\n",
    "\n",
    "    df2 = pd.read_csv(\"/Users/ditlswin/Documents/rkaul/traffic_flow_predi/TrafficFlowPrediction-master/data/rain_weekend.csv\", encoding='utf-8').fillna(0)\n",
    "   \n",
    "    date = np.array(df.iloc[:,2])\n",
    "    weekend = get_weekend_data(date[0],date[-1])\n",
    "    \n",
    "    rain_date = df2['date']\n",
    "    rainfall_data = df2['rain_mm']\n",
    "    rainfall_data = normalize(rainfall_data[:,np.newaxis], axis=0).ravel()\n",
    "    rainfall_data = rain_data(rain_date, rainfall_data,date)\n",
    "    \n",
    "  \n",
    "    weekend = list([item]*NUMERIC_DAY for item in weekend)\n",
    "    weekend = np.array(weekend)  \n",
    "    weekend = weekend.ravel()\n",
    "  \n",
    "    rainfall_data = list([item]*NUMERIC_DAY for item in rainfall_data)\n",
    "    rainfall_data = np.array(rainfall_data)  \n",
    "    rainfall_data = rainfall_data.ravel()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#   read all the vehicle/15min in one array   \n",
    "    flow = np.array(df.iloc[:,3:])\n",
    "    flow = flow.ravel()\n",
    "    max_data = flow.shape[0]\n",
    "    weekend = weekend[:max_data]\n",
    "    rainfall_data = rainfall_data[:max_data]\n",
    "    \n",
    "    \n",
    "#     normalize all the values  \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1)).fit(flow.reshape(-1, 1))\n",
    "    normalized_flow = scaler.transform(flow.reshape(-1, 1)).reshape(1, -1)[0]\n",
    "    \n",
    "#     append all data together\n",
    "    normalized_flow = np.vstack([normalized_flow, rainfall_data,weekend])\n",
    "\n",
    "\n",
    "#     splitting the file into train and test dataset\n",
    "    split = int(normalized_flow.shape[1] * 0.8)\n",
    "    \n",
    "    flow1 = normalized_flow[:,:split]\n",
    "    flow2 = normalized_flow[:,split:]\n",
    "    \n",
    "    \n",
    "    train, test = [], []\n",
    "    for i in range(lags, flow1.shape[1]):\n",
    "        train.append(flow1[:,i - lags: i + 1])\n",
    "    for i in range(lags, flow2.shape[1]):\n",
    "        test.append(flow2[:,i - lags: i + 1])\n",
    "\n",
    "    train = np.array(train)\n",
    "    test = np.array(test)\n",
    "    np.random.shuffle(train)\n",
    "\n",
    "    X_train = train[:, :, :-1]\n",
    "#     print(X_train.shape)\n",
    "    y_train = train[:, 0, -1]\n",
    "#     print(y_train)\n",
    "    X_test = test[:, :, :-1]\n",
    "    y_test = test[:, 0, -1]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.025863030005593587, 0.025863030005593587, 0.0, 0.051726060011187174, 0.0, 0.051726060011187174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025863030005593587, 0.0, 0.0, 0.1551781800335615, 0.0, 0.0, 0.0, 0.051726060011187174, 0.0, 0.0, 0.9827951402125562, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test, scaler = process_data(\"970_1_data.csv\", 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.73333333, 0.72666667, 0.61333333, ..., 0.73555556,\n",
       "         0.65777778, 0.67111111],\n",
       "        [0.02586303, 0.02586303, 0.02586303, ..., 0.02586303,\n",
       "         0.02586303, 0.02586303],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ]],\n",
       "\n",
       "       [[0.04666667, 0.02444444, 0.03555556, ..., 0.00888889,\n",
       "         0.00888889, 0.00222222],\n",
       "        [0.02586303, 0.02586303, 0.02586303, ..., 0.02586303,\n",
       "         0.02586303, 0.02586303],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ]],\n",
       "\n",
       "       [[0.74888889, 0.64444444, 0.61555556, ..., 0.61777778,\n",
       "         0.67777778, 0.67111111],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.20888889, 0.24666667, 0.20666667, ..., 0.04      ,\n",
       "         0.04      , 0.06      ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [1.        , 1.        , 1.        , ..., 0.        ,\n",
       "         0.        , 0.        ]],\n",
       "\n",
       "       [[0.62222222, 0.77111111, 0.65555556, ..., 0.66      ,\n",
       "         0.56444444, 0.68      ],\n",
       "        [0.05172606, 0.05172606, 0.05172606, ..., 0.05172606,\n",
       "         0.05172606, 0.05172606],\n",
       "        [1.        , 1.        , 1.        , ..., 1.        ,\n",
       "         1.        , 1.        ]],\n",
       "\n",
       "       [[0.00222222, 0.00888889, 0.02444444, ..., 0.05777778,\n",
       "         0.12666667, 0.12666667],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
